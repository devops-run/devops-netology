# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

### Решение.

- Cписок операций для остановки запроса пользователя.        

1. Поиск и остановка запроса:      

Определяем список запросов, выполняющихся больше 3-х минут:     
```
db.currentOp({"secs_running":{$gte: 180}})  

```

2. Определяем необходимый opid и прерываем его:     
```
db.killOp(opid) 
```
- Вариант решения проблемы с долгими/зависающими запросами в MongoDB:

Решение - использовать профилировщик базы данных.     
Профилировщик базы данных собирает детализированные данные о запросах MongoDB дольше, чем определенный порог — порог в миллисекундах, при котором профилировщик базы данных считает запрос медленным. Профилировщик базы данных записывает все собранные данные в system.profileколлекцию, чтобы мы могли проанализировать их позже.    
    
Также можно установить некоторое большее значение в качестве порога, чтобы минимизировать количество запросов для анализа.      
Например, следующая команда устанавливает уровень профилирования для текущей базы данных равным 1, а порог медленной работы равен 1000 миллисекунд:
```
user:PRIMARY> db.setProfilingLevel(1, 1000)
{ “was” : 0, “slowms” : 100, “ok” : 1 }
user:PRIMARY> db.getProfilingStatus()
{ “was” : 1, “slowms” : 1000 }
```

База данных будет регистрировать операции медленнее, чем 1000 миллисекунд в system.profileсборе.        
    
Теперь можно запрашивать данные по этой коллекции и анализировать:      
```
db.system.profile.find().pretty()
// or get 'query' operations only and specified fields
db.system.profile.find( { op: { $eq : 'query' } } , {"millis": 1, "ns": 1, "ts": 1,"query": 1}).sort( { ts : -1 } ).pretty()
```
Для решения использовал официальную документацию и [данную статью](https://medium.com/mongodb-cowboys/troubleshooting-mongodb-100-cpu-load-and-slow-queries-da622c6e1339).

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?
 
#### Решение

Рост “новых” пар ключ-значение по отношению к тем, которые должны быть очищены говорит о том, что растет размер хранилища, а значит ресурс памяти заканчивается. Блокировка на запись, скорее всего, говорит о том, то выделенная память закончилась. 
    
Решением, на мой взгляд, может быть настройка параметров отвечающих за "Распределение памяти".

Maxmemory configuration directive

For example, to configure a memory limit of 100 megabytes, you can use the following directive inside the redis.conf file:

maxmemory 100mb  


Если maxmemory параметр не установлен, Redis будет продолжать выделять память по своему усмотрению и, таким образом, может (постепенно) поглотить всю свободную память. Поэтому обычно рекомендуется настроить некоторый лимит. Вы также можете установить maxmemory-policy значение noeviction (которое не является значением по умолчанию в некоторых старых версиях Redis).

(для ответа использовал материалы с  Redis latency troobleshooting, на практике не проаерял)    

   

## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

#### Решение

Чаще всего данная ситуация возникает, когда происходит выборка очень большого количества данных, т.к. проблема стала возникать не сразу, а при росте количества записей.
В качестве решения можно предложить:
   1. Увеличить значение параметров : connect_timeout, interactive_timeout, wait_timeout    
   2. Добавить ресурсов на машине   
   3. Создать индексы для оптимизации  и ускорения запросов (определить по плану запросов)  
    
Документация рекомендует нам увеличить настройку net_read_timeout с дефолтных 30 до 60 секунд, но делать это стоит только после того, как закончились пути оптимизация запроса с помощью индексов и других средств БД.


Так же могут быть сбои на сетевой инфраструктуре, в таком случае необходимо увеличивать net_read_timeout (https://dev.mysql.com/doc/refman/5.7/en/error-lost-connection.html).
Как дополнительный вариант можно расширить максимальное число соединений :  max_connections (https://www.opennet.ru/docs/RUS/sql_error/chap10.html).

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

#### Решение
Судя по всему oom-killer  завершает процесс.    
Чаще всего это происходит т.к  заканчивается пространство на диске или память.       
Если закончилось пространство на диске, выход один — освободить место и перезапустить базу данных.  

Если проблема в нехватке RAM - Добавить память, + тонко настроить базу на использование RAM.  
Также можно установить для vm.overcommit_memory значение 2.     
Это не гарантирует, что OOM-Killer не придется вмешиваться, но снизит вероятность принудительного завершения процесса PostgreSQL.


